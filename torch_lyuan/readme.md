using distributed to speed up training
# how to run
1. setting dataset path and other config in config_train.py
2. fix node numbers and the path of train_distributed.py in dist_train.sh
3. bash dist_train.sh
